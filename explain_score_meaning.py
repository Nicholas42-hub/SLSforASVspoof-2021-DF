#!/usr/bin/env python
"""
解释 discrimination score 的取值范围和意义
"""

import torch
import numpy as np
import matplotlib.pyplot as plt

print("=" * 70)
print("Discrimination Score 的含义和取值范围")
print("=" * 70)

print("\n【公式】")
print("score = |bonafide_mean_activation - spoof_mean_activation|")
print()
print("其中 activation 是 TopK SAE 经过 ReLU 后的输出值")

print("\n【取值范围】")
print("-" * 70)
print("理论范围: [0, +∞)")
print("  - 0: 该feature在bonafide和spoof上激活完全相同（无判别力）")
print("  - +∞: 理论上无上限")
print()
print("实际范围: 通常在 [0, 几] 之间")
print("  原因: 神经网络的激活值经过ReLU后，虽然无上限，但实际值不会太大")

print("\n【实际数据分析】")
print("-" * 70)

# 模拟一些实际的激活值分布
np.random.seed(42)

# 不同discriminative程度的features
print("\n场景1: 完全无判别力的feature (score ≈ 0)")
bonafide = np.random.uniform(0.3, 0.5, 250)
spoof = np.random.uniform(0.3, 0.5, 250)
score = abs(bonafide.mean() - spoof.mean())
print(f"  Bonafide平均: {bonafide.mean():.4f}")
print(f"  Spoof平均: {spoof.mean():.4f}")
print(f"  Score: {score:.4f} ← 两者几乎相同，无法区分")

print("\n场景2: 弱判别力 (score ≈ 0.05)")
bonafide = np.random.uniform(0.4, 0.6, 250)
spoof = np.random.uniform(0.3, 0.5, 250)
score = abs(bonafide.mean() - spoof.mean())
print(f"  Bonafide平均: {bonafide.mean():.4f}")
print(f"  Spoof平均: {spoof.mean():.4f}")
print(f"  Score: {score:.4f} ← 有差异但不明显")

print("\n场景3: 中等判别力 (score ≈ 0.1, 你的模型)")
bonafide = np.random.uniform(0.5, 0.8, 250)
spoof = np.random.uniform(0.3, 0.6, 250)
score = abs(bonafide.mean() - spoof.mean())
print(f"  Bonafide平均: {bonafide.mean():.4f}")
print(f"  Spoof平均: {spoof.mean():.4f}")
print(f"  Score: {score:.4f} ← 有明显差异，可用于区分")

print("\n场景4: 强判别力 (score ≈ 0.5)")
bonafide = np.random.uniform(0.8, 1.2, 250)
spoof = np.random.uniform(0.2, 0.5, 250)
score = abs(bonafide.mean() - spoof.mean())
print(f"  Bonafide平均: {bonafide.mean():.4f}")
print(f"  Spoof平均: {spoof.mean():.4f}")
print(f"  Score: {score:.4f} ← 差异非常大，判别力很强")

print("\n场景5: 极强判别力 (score = 1.0)")
bonafide = np.random.uniform(1.5, 2.0, 250)
spoof = np.random.uniform(0.3, 0.7, 250)
score = abs(bonafide.mean() - spoof.mean())
print(f"  Bonafide平均: {bonafide.mean():.4f}")
print(f"  Spoof平均: {spoof.mean():.4f}")
print(f"  Score: {score:.4f} ← 差异巨大，完美区分！")

print("\n场景6: 理论极限 (score >> 1.0)")
print("  如果某个feature在bonafide上激活值=5.0，spoof上=0.1")
print("  Score = |5.0 - 0.1| = 4.9")
print("  → 这意味着该feature几乎只在bonafide上激活")
print("  → 实际中很少见，因为网络会学习更平衡的表示")

print("\n" + "=" * 70)
print("【Score = 1.0 的意义】")
print("=" * 70)
print()
print("如果你的模型有 discrimination score = 1.0 的feature:")
print()
print("✓ 意义重大:")
print("  - 该feature在两类样本上的激活差异非常显著")
print("  - 可以作为一个强有力的判别指标")
print("  - 接近理想的线性可分特征")
print()
print("✓ 实际效果:")
print("  - 仅凭这一个feature，可能就能达到很好的分类效果")
print("  - 如果用这个feature做简单的阈值分类，准确率会很高")
print()
print("✓ 可解释性:")
print("  - 这个feature对应的acoustic pattern非常distinctive")
print("  - bonafide和spoof在这个维度上有本质区别")

print("\n" + "=" * 70)
print("【你的模型的情况】")
print("=" * 70)
print()
print("你的模型:")
print("  - 最强feature score ≈ 0.10")
print("  - 平均top 50 score ≈ 0.065")
print()
print("评价:")
print("  ✓ Score 0.1 已经是有意义的判别力")
print("  ⚠️ 距离 1.0 还有距离，说明:")
print("     - 单个feature的区分度有限")
print("     - 需要多个features组合才能达到好的性能")
print("     - 这实际上是好事！说明模型学习了distributed representation")
print("     - 而不是过度依赖少数几个features")
print()
print("对比:")
print("  - Score < 0.05: 几乎没有判别力")
print("  - Score 0.05-0.1: 有一定判别力（你的模型在这里）")
print("  - Score 0.1-0.5: 强判别力")
print("  - Score 0.5-1.0: 非常强的判别力")
print("  - Score > 1.0: 极强判别力（罕见）")

print("\n" + "=" * 70)
print("【实际建议】")
print("=" * 70)
print()
print("如何提升 discrimination score:")
print("  1. 增大 sae_weight (从0.1到0.2或0.5)")
print("     → 让SAE学习更discriminative的features")
print()
print("  2. 调整 k 值")
print("     → k更小(如64) = 更稀疏 = 可能更discriminative")
print("     → k更大(如256) = 更密集 = 更多细节但可能less discriminative")
print()
print("  3. 更多训练")
print("     → 当前epoch 20/40，继续训练可能改善")
print()
print("但注意:")
print("  - 过高的score可能意味着overfitting")
print("  - 当前0.1左右的score + 6.93% EER是一个好的平衡点")
print("  - 追求极高的score不一定带来更好的泛化性能")
